---
layout: post
title:  "Us and Ourselves"
date:   27-08-2020
image:  "/images/nerves.jpg"
teaser: "What does it mean for something to be conscious? What even is consciousness? How does our brain give rise to it?"
---
<img src="{{ site.baseurl }}/images/nerves.jpg" class="fit image">

Consciousness is a term that is quite intuitive to every human being, yet if you are to ask anyone to provide you with a 
definition, you will receive broad and fuzzy description. The Oxford Languages dictionary defines consciousness as _"The 
fact of awareness by the mind of itself and the world"_. However, this simplification does not do justice to the large 
collection of literature that has been built on the subject.

Many schools of thought have provided a variety of competing ideas that aim to better understand what it is that gives 
rise to the process through which we experience our surroundings and our mind's inner mechanisms. The most unsettling 
part is not that we can't seem to discover the precise answers to our sentience, it is the fact that we don't even know 
what are the questions we should be asking.

What is consciousness? Why is it, evolutionarily speaking, beneficial for consciousness to develop? Where is the line 
between a conscious system and a non-conscious one? Is it even possible to objectively determine whether anything is 
conscious?

To begin answering these questions, we should first note that the term 'consciousness' gets thrown around under multiple 
distinct meanings. The <a href="https://plato.stanford.edu/entries/consciousness/#ConCon">Standford Encyclopedia</a> 
defines two general ideas: **_Creature consciousness_** and **_State consciousness_**. The former has to do with the 
level of awareness we associate to an external creature, while the latter is the notion we use to describe the mental 
state that a being is currently in.  The Standford page goes into much deeper detail that I can possibly explore in this 
post, and I recommend you give it a read if your want a nice introduction into this field of philosophy.

<br>
#### <u>Creature consciousness and the issue with definitions</u>
Lets say we define consciousness as awareness of one's environment and it's internal states. Perhaps a simpler way to 
explore consciousness is by trying to comparing the levels of consciousness of different entities. On the one side, 
everyone would agree that a simple stone is not at all conscious. However, what about a mouse? Ok, maybe a mouse is 
conscious enough to deserve the term, but what about a spider? Spiders are capable of navigating their surroundings, as 
well as being aware of their inner biological needs. So maybe we can squeeze spiders under the 'consciousness' umbrella? 
What about single-celled organisms? What I'm getting at here is that maybe this form consciousness can be seen as a 
spectrum with inanimate objects on one side and complex intelligence beings on the other. Maybe over many small 
incremental states, evolution has climbed this scale from inanimate unicellular processes, to somewhat-conscious simple 
multicellular organisms, to the complex intelligent apes we are today.

The youtube channel **In a Nutshell** has a <a href="https://youtu.be/H6u0VBqNBQ8">very nice video</a> on this very 
idea. The first step towards consciousness is possibly a unicelullar being capable of reacting to the level of food in 
its environment. Reacting to inner states such as the level of hunger yields advantages in the evolutionary process. 
Furthermore, being aware of your surroundings, as well as building an inner representation of the world around you 
allows for navigating towards food sources. Soon after, we start having complex creatures with ever-more developed 
cognitive functions that will eventually resemble organisms that we more traditionally refer to as 'conscious'.

But this definition is not without its controversy. Some have argued that under this definition a simple transistor would 
meet the most basic interpretation of consciousness, since the transistor is aware of its inner state and reacts to the 
environment according to this inner state. We, of course, don't go around treating transistors as if they were conscious 
beings, but it makes you wonder what other systems fit this definition of consciousness. Another example of a type of 
edge case to this definition are superorganisms such as bee colonies. One can argue that a bee colony meets the criteria 
for consciousness. The colony is aware of its biological needs and desires, and reacts accordingly with its surroundings.
In the other hand, human society behaves in a similar way but we wouldn't go around referring to our cities as conscious 
beings.

This brings me to another issue with consciousness: We have trouble pinpointing where consciousness is localized. You 
yourself, a conscious creature, are here thanks to the thing you call a brain. However, the brain is just a collection 
of neurons, which we wouldn't refer to as individual conscious entities. So where do YOU exist? Are you the network of 
neurons that make up your brain? Are you the electrical pattern continuously firing in your brain? Perhaps both? 
Unfortunately there is no easy answer to these question, and every attempt to search deeper into this issue only brings 
forth further questions.

Say, for instance, that we consider the cognitive processes that go on in someone's mind to be correlated with some 
measure of being conscious. Is it correct to say that consciousness is located in the brain? And if so, which regions of 
the brain are necessary for consciousness? The information processing necessary for plenty of motor responses that we 
exhibit don't necessarily take place in the brain at all. Whenever you accidentally burn yourself, the information 
perceived at your limbs travels to the spinal cord, where an action is automatically taken before the signal is even 
able to reach your brain. These kinds of evidence seem to imply that the collection of matter that gives rise to 
consciousness has very fuzzy borders. This issue, however, have even weirder implications.

Take a person, let's call him Adam, who had a serious brain injury that lead to him having anterograde amnesia and thus 
losing the ability to create new long-term memories. He however, carries around a notebook where he writes down all important 
information he wants to recall later in the day, and for all intents and purposes, he is able to lead a normal day-to-day 
life. Lets take another person, Bob, who has never suffered from such an injury and is able to recall from his long-term 
memory normally. We could argue that Adam's notebook is equivalent to the part of Bob's brain responsible for storing 
memories. Is this notebook part of the conscious entity that makes up Adam? At the end of the day, part 
of the internal state of Adam lives in the notebook. 

If you think the previous example is some far-fetched edge case, think again. In philosophy, the idea of **enactivism** 
claims that cognition is not exclusively tied to the working of an 'inner mind', and that a mind, if able to, will 
prefer to push cognitive processes outside of the brain. This is exactly what we see happen in daily lives when we, 
for example, push simple mathematical operations onto our calculators. The same could be said about hiring a secretary, 
part of your cognition could be said to live within your secretary. Now, one could argue that these example are 
not permanently part of someone's cognitive workspace, and so calling it part of that person's consciousness is not fair.
However, I want you to think about the ever-increasing level of reliance we have on our smartphones. They are becoming 
ever-present in our lives. Our smartphones are already learning about our needs and desires, about the way we think and 
behave... how long until they become an inseparable part of our minds? 
 

#### <u>State consciousness and the subjective experience</u>


Material of consciousness, machines, simulations, simulated worm nervous system.
